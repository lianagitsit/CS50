#!/usr/bin/env python3

import os
import sys

from analyzer import Analyzer
from termcolor import colored
from helpers import get_user_timeline
from nltk.tokenize import TweetTokenizer

def main():

    # ensure proper usage
    if len(sys.argv) != 2:
        sys.exit("Usage: ./tweets @screen_name")

    # absolute paths to lists
    positives = os.path.join(sys.path[0], "positive-words.txt")
    negatives = os.path.join(sys.path[0], "negative-words.txt")

    # get tweets
    t = sys.argv[1].lstrip("@")
    tweets = get_user_timeline(t)
    # tweets = t.lstrip("@")
    if tweets == None:
        sys.exit("Invalid entry, please try again.")
        
    tknzr = TweetTokenizer()
    # instantiate analyzer
    analyzer = Analyzer(positives, negatives)
    
    for tweet in tweets:
        print(tknzr.tokenize(tweet))
        # analyze tweet
        score = analyzer.analyze(tweet)
        if score > 0.0:
            print(colored(":)", "green"))
        elif score < 0.0:
            print(colored(":(", "red"))
        else:
            print(colored(":|", "yellow"))
    
if __name__ == "__main__":
    main()
